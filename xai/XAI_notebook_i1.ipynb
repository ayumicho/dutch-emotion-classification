{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for Explainable AI for Transformer Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to get you started on applying explainable AI techniques on your Transformer Model. The code is based on the work described in the paper \"XAI for Transformers: Better Explanations through Conservative Propagation\" by Ali et al. (2022), to be found here: https://proceedings.mlr.press/v162/ali22a/ali22a.pdf and this is the link to the official repository on Github: https://github.com/AmeenAli/XAI_Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Create the 'figures' directory if it does not exist\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load your test dataset (adjust the path accordingly)\n",
    "df = pd.read_csv(\"../Task5/Datasets/test.csv\")\n",
    "\n",
    "# Confirm expected columns exist\n",
    "assert 'main_emotion' in df.columns and 'Corrected Sentence' in df.columns, \"Dataset must include 'main_emotion' and 'Corrected Sentence' columns.\"\n",
    "\n",
    "# Get 3 representative samples per emotion (results in 6x3 sentences if 6 emotions are available)\n",
    "emotion_samples = {}\n",
    "for emotion in df['main_emotion'].unique():\n",
    "    samples = df[df['main_emotion'] == emotion].sample(n=min(3, len(df[df['main_emotion'] == emotion])), random_state=42)['Corrected Sentence'].tolist()\n",
    "    emotion_samples[emotion] = samples\n",
    "\n",
    "# Flatten into a list of (sentence, emotion) tuples.\n",
    "selected_sentences = [(text, label) for label, texts in emotion_samples.items() for text in texts]\n",
    "print(f\"Collected {len(selected_sentences)} samples across {len(emotion_samples)} emotions.\")\n",
    "\n",
    "# Map for numerical model predictions\n",
    "# Based on your test results + educated guesses for missing labels\n",
    "label_map = {\n",
    "    0: \"anger\",\n",
    "    1: \"happiness\",    # Assuming LABEL_1 is happiness (most common remaining)\n",
    "    2: \"fear\",\n",
    "    3: \"surprise\",\n",
    "    4: \"neutral\",     \n",
    "    5: \"sadness\",\n",
    "    6: \"disgust\"\n",
    "}\n",
    "\n",
    "\n",
    "# Convert numeric labels to strings\n",
    "df['main_emotion'] = df['main_emotion'].map(label_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗NB: This code works for models based on the BERT architecture. If you used a different transformer architecture (DistilBERT, RoBERTa, etc.), you might need to adapt some of the code to fit the architecutre requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and model correctly\n",
    "model_name = \"wietsedv/bert-base-dutch-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the base model\n",
    "model = BertForSequenceClassification.from_pretrained(\"../Task5/bertje_emotion_classifier\") # Adjust num_labels if needed\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient x Input\n",
    "\n",
    "The gradient_x_input function calculates token relevance using the Gradient × Input method. It converts input IDs to embeddings and enables gradient tracking. The embeddings are passed through the model, generating logits for prediction. The function computes gradients with respect to the predicted class, indicating how sensitive the prediction is to each token. If no gradients are computed, it raises an error to signal that the embeddings are not properly linked to the output. The gradients are multiplied by the input embeddings to calculate relevance scores, showing how much each token influenced the model’s prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_x_input(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "    Compute the relevance of each token via Gradient x Input.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Tokenize and retrieve input IDs and attention mask\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    \n",
    "    # Get the input embeddings from the model's embedding layer.\n",
    "    inputs_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
    "    # Ensure the embeddings require gradients\n",
    "    inputs_embeds = inputs_embeds.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # Pass embeddings to the model.\n",
    "    outputs = model(inputs_embeds=inputs_embeds, attention_mask=inputs['attention_mask'])\n",
    "    # Predicted class based on logits\n",
    "    pred_class = outputs.logits.argmax(dim=-1)\n",
    "    # Select the logit corresponding to the predicted class.\n",
    "    output = outputs.logits[0, pred_class]\n",
    "\n",
    "    # Backward pass: get gradients with respect to the input embeddings.\n",
    "    output.backward()\n",
    "    grads = inputs_embeds.grad\n",
    "\n",
    "    # Compute relevance: element-wise multiplication and sum across embedding dimensions.\n",
    "    relevance = (inputs_embeds * grads).sum(dim=-1).squeeze()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs.input_ids[0])\n",
    "    \n",
    "    return tokens, relevance.detach().numpy(), pred_class.item()\n",
    "\n",
    "import os\n",
    "\n",
    "def plot_relevance(tokens, relevance, title, emotion_label, filename):\n",
    "    \"\"\"\n",
    "    Plot a bar graph of token relevance.\n",
    "    Highlights tokens with a relevance above the 75th percentile.\n",
    "    \"\"\"\n",
    "    # Ensure the 'figuresi1' directory exists\n",
    "    os.makedirs('figuresi1', exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 3))\n",
    "    # Mark tokens with high absolute relevance with red\n",
    "    threshold = np.percentile(np.abs(relevance), 75)\n",
    "    colors = ['red' if abs(r) >= threshold else 'grey' for r in relevance]\n",
    "    plt.bar(range(len(tokens)), relevance, color=colors)\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation=45, fontsize=10)\n",
    "    plt.title(f\"{title} (Emotion: {emotion_label})\", fontsize=12)\n",
    "    plt.ylabel(\"Relevance Score\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figuresi1/{filename}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Run Gradient x Input for each selected sentence\n",
    "# First, generate all plots\n",
    "for idx, (text, true_label) in enumerate(selected_sentences):\n",
    "    tokens, relevance, pred_class = gradient_x_input(model, tokenizer, text)\n",
    "    id2label = {v: k for k, v in label_map.items()}\n",
    "    predicted_emotion = label_map.get(pred_class, f'class_{pred_class}')\n",
    "    plot_relevance(tokens, relevance, f\"Sentence {idx+1}\", predicted_emotion, f\"gradient_x_input_{predicted_emotion}_{idx}\")\n",
    "\n",
    "# Then, print all the details\n",
    "for idx, (text, true_label) in enumerate(selected_sentences):\n",
    "    tokens, relevance, pred_class = gradient_x_input(model, tokenizer, text)\n",
    "    key_tokens = [tok for tok, rel in zip(tokens, relevance) if abs(rel) > 0.2]\n",
    "    predicted_emotion = label_map.get(pred_class, f'class_{pred_class}')\n",
    "    print(f\"Emotion: {predicted_emotion}\\nSentence: {text}\\nKey Tokens: {key_tokens}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conservative Propagation\n",
    "\n",
    "The ``modified_attention_forward`` function adjusts attention propagation by calculating attention scores using scaled dot product attention. It computes attention probabilities through softmax, then multiplies them with hidden states to get the context layer. Relevance scores are propagated back through the attention weights, to ensure a conservative flow of information. The ``modified_layernorm_forward`` function normalizes hidden states using the mean and variance, then redistributes relevance based on the normalization values. This follows the paper’s conservative propagation strategy, which stabilizes relevance flow through transformers by correcting how relevance is handled in attention and layer normalization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_attention_forward(attention_layer, hidden_states, relevance_scores, tokens, save_filename=None):\n",
    "    \"\"\"\n",
    "    Modified forward pass for the attention layer that applies Conservative Propagation.\n",
    "    Visualizes the attention probabilities using a heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "        attention_layer: the specific attention layer (e.g., model.bert.encoder.layer[0].attention.self)\n",
    "        hidden_states: the input hidden states for the layer\n",
    "        relevance_scores: the current relevance scores (starting at the output)\n",
    "        tokens: list of tokens corresponding to the hidden states\n",
    "        save_filename: if provided, saves the heatmap figure under 'figures/{save_filename}.png'\n",
    "    \n",
    "    Returns:\n",
    "        context_layer: the result after attention\n",
    "        propagated_relevance: the updated relevance scores after propagation\n",
    "    \"\"\"\n",
    "    # Compute raw attention scores and apply softmax to get probabilities.\n",
    "    attention_scores = (hidden_states @ hidden_states.transpose(-1, -2)) / hidden_states.size(-1)**0.5\n",
    "    attention_probs = attention_scores.softmax(dim=-1).detach()\n",
    "    context_layer = attention_probs @ hidden_states\n",
    "\n",
    "    # Propagate relevance back using the attention probabilities.\n",
    "    propagated_relevance = (attention_probs.transpose(-1, -2) @ relevance_scores)\n",
    "    \n",
    "    # Visualize the attention probabilities as a heatmap.\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attention_probs[0].detach().numpy(), cmap='coolwarm', xticklabels=tokens, yticklabels=tokens)\n",
    "    plt.title('Attention Scores Heatmap')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure if a filename is provided.\n",
    "    if save_filename:\n",
    "        plt.savefig(f\"figuresi1/{save_filename}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return context_layer, propagated_relevance\n",
    "\n",
    "def modified_layernorm_forward(layernorm_layer, hidden_states, relevance_scores):\n",
    "    \"\"\"\n",
    "    Modified forward pass for layer normalization with Conservative Propagation.\n",
    "    \n",
    "    Returns the normalized hidden states and updated relevance scores.\n",
    "    \"\"\"\n",
    "    mean = hidden_states.mean(-1, keepdim=True)\n",
    "    variance = hidden_states.var(-1, keepdim=True, unbiased=False)\n",
    "    normed = (hidden_states - mean) / (variance + layernorm_layer.eps).sqrt()\n",
    "    propagated_relevance = relevance_scores / (variance + layernorm_layer.eps).sqrt()\n",
    "    return normed.detach(), propagated_relevance\n",
    "\n",
    "# Process each selected sentence for Step 2 (Modified Attention Propagation)\n",
    "for idx, (text, true_label) in enumerate(selected_sentences):\n",
    "    # Tokenize the text and get input embeddings.\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    inputs_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
    "    hidden_states = inputs_embeds.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Run a forward pass to compute model outputs.\n",
    "    outputs = model(inputs_embeds=hidden_states, attention_mask=inputs['attention_mask'])\n",
    "    predicted_class = outputs.logits.argmax(dim=-1)\n",
    "    \n",
    "    # Initialize relevance scores.\n",
    "    relevance_scores = torch.zeros_like(hidden_states)\n",
    "    # A simple initialization: assign the model's logit for the predicted class to the last token.\n",
    "    relevance_scores[:, -1, :] = outputs.logits[:, predicted_class].unsqueeze(-1)\n",
    "    \n",
    "    # Convert token IDs to tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs.input_ids[0])\n",
    "    \n",
    "    # Run modified attention propagation on the first encoder layer.\n",
    "    heatmap_filename = f\"modified_attention_sample_{idx+1}\"\n",
    "    context_layer, propagated_relevance = modified_attention_forward(\n",
    "        model.bert.encoder.layer[0].attention.self,\n",
    "        hidden_states,\n",
    "        relevance_scores,\n",
    "        tokens,\n",
    "        save_filename=heatmap_filename\n",
    "    )\n",
    "    \n",
    "    # Optional: You can also apply modified_layernorm_forward to further process the propagated relevance.\n",
    "    # For example:\n",
    "    normed, relevance_normed = modified_layernorm_forward(model.bert.encoder.layer[0].output.LayerNorm, context_layer, propagated_relevance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pertubating\n",
    "\n",
    "Perturbating means deliberately modifying or disturbing the input data to observe how the model's prediction changes. It helps identify which parts of the input are most influential by measuring the model's sensitivity to these changes. The ``perturb_input_and_evaluate`` function measures how sensitive the model’s prediction is to specific tokens by progressively modifying the input. It first tokenizes the input text and sorts tokens based on their relevance scores. If perturb_type is 'remove', the **least** relevant tokens are removed first; otherwise, the **most relevant** tokens are removed first. Tokens are replaced with [PAD] to maintain input length consistency. The modified texts are converted back into input tensors and passed through the model. The model’s confidence in its prediction is recorded after each perturbation using softmax probabilities. This allows evaluation of how much each token contributes to the final prediction by observing how the model’s confidence changes as tokens are progressively masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_input_and_evaluate(model, tokenizer, text, relevance_scores, perturb_type='remove'):\n",
    "    \"\"\"\n",
    "    Perturb the input text by removing tokens based on relevance scores and evaluate the model's confidence.\n",
    "    \n",
    "    Parameters:\n",
    "        model: the Transformer model\n",
    "        tokenizer: the tokenizer corresponding to the model\n",
    "        text: the input text to perturb\n",
    "        relevance_scores: the relevance scores used for determining token importance\n",
    "        perturb_type: 'remove' to remove least relevant tokens first,\n",
    "                      or any other value to remove most relevant tokens first.\n",
    "    \n",
    "    Returns:\n",
    "        confidences: a list of confidence scores after successive perturbations.\n",
    "    \"\"\"\n",
    "    # Tokenize the text to get a list of tokens.\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Compute the norm of the relevance score for each token.\n",
    "    token_relevance_norm = torch.norm(relevance_scores[0], dim=-1)\n",
    "    \n",
    "    if perturb_type == 'remove':\n",
    "        # Remove tokens with lower relevance first.\n",
    "        sorted_indices = torch.argsort(token_relevance_norm, descending=False)\n",
    "    else:\n",
    "        # Remove tokens with higher relevance first.\n",
    "        sorted_indices = torch.argsort(token_relevance_norm, descending=True)\n",
    "        \n",
    "    sorted_indices = sorted_indices.tolist()\n",
    "\n",
    "    perturbed_texts = []\n",
    "    # Iteratively remove tokens based on sorted relevance.\n",
    "    for i in range(1, len(tokens) + 1):\n",
    "        perturbed_tokens = tokens.copy()\n",
    "        for idx in sorted_indices[:i]:\n",
    "            if idx < len(perturbed_tokens):\n",
    "                perturbed_tokens[idx] = '[PAD]'\n",
    "        perturbed_text = tokenizer.convert_tokens_to_string(perturbed_tokens)\n",
    "        perturbed_texts.append(perturbed_text)\n",
    "\n",
    "    confidences = []\n",
    "    # Evaluate model confidence on each perturbed text.\n",
    "    for pert_text in perturbed_texts:\n",
    "        pert_inputs = tokenizer(pert_text, return_tensors='pt')\n",
    "        pert_output = model(**pert_inputs)\n",
    "        confidence = pert_output.logits.softmax(dim=-1).max().item()\n",
    "        confidences.append(confidence)\n",
    "\n",
    "    return confidences\n",
    "\n",
    "# Process each selected sentence for Step 3 (Input Perturbation)\n",
    "for idx, (text, true_label) in enumerate(selected_sentences):\n",
    "    # Tokenize and get embeddings for the sentence.\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    inputs_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
    "    hidden_states = inputs_embeds.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass to get outputs and predicted class.\n",
    "    outputs = model(inputs_embeds=hidden_states, attention_mask=inputs['attention_mask'])\n",
    "    predicted_class = outputs.logits.argmax(dim=-1)\n",
    "    \n",
    "    # Initialize relevance scores as in the previous step.\n",
    "    relevance_scores = torch.zeros_like(hidden_states)\n",
    "    relevance_scores[:, -1, :] = outputs.logits[:, predicted_class].unsqueeze(-1)\n",
    "    \n",
    "    # Calculate token-level perturbation confidences.\n",
    "    confidences_remove = perturb_input_and_evaluate(model, tokenizer, text, relevance_scores, perturb_type='remove')\n",
    "    \n",
    "    # Tokenize the sentence to get tokens for the x-axis.\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    min_length = min(len(tokenized_text), len(confidences_remove))\n",
    "    \n",
    "    # Plot the model confidence as tokens are removed.\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(range(1, min_length + 1), confidences_remove[:min_length], marker='o', color='blue')\n",
    "    plt.axhline(y=0.5, color='red', linestyle='--', label=\"50% Confidence Threshold\")\n",
    "    plt.fill_between(\n",
    "        range(1, min_length + 1),\n",
    "        confidences_remove[:min_length],\n",
    "        0.5,\n",
    "        where=(np.array(confidences_remove[:min_length]) < 0.5),\n",
    "        color='red',\n",
    "        alpha=0.2\n",
    "    )\n",
    "    plt.title(f\"Model Confidence During Token Removal for Sentence {idx+1}\")\n",
    "    plt.xlabel(\"Number of Tokens Removed\")\n",
    "    plt.ylabel(\"Confidence\")\n",
    "    plt.legend()\n",
    "    \n",
    "    confidence_plot_filename = f\"confidence_removal_sentence_{idx+1}\"\n",
    "    plt.savefig(f\"figuresi1/{confidence_plot_filename}.png\", bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/XAI_Analysis_Dutch_BERT.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 116\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Save the markdown as a file\u001b[39;00m\n\u001b[0;32m    115\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data/XAI_Analysis_Dutch_BERT.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    117\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(xai_markdown)\n\u001b[0;32m    119\u001b[0m output_path\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\envs\\Y2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/XAI_Analysis_Dutch_BERT.md'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Y2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
